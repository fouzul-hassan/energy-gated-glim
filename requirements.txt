# GLIM: Grounded Language-Image Model for EEG-to-Text
# Requirements for training and inference
# Compatible with Python 3.10+

# =============================================================================
# Core Deep Learning
# =============================================================================
torch>=2.0.0
lightning>=2.0.0
torchmetrics>=1.0.0

# =============================================================================
# Transformers & NLP
# =============================================================================
transformers>=4.35.0
tokenizers>=0.15.0
sentencepiece>=0.1.99

# =============================================================================
# Vision Models
# =============================================================================
timm>=0.9.0

# =============================================================================
# Data Processing
# =============================================================================
numpy>=1.24.0
pandas>=2.0.0
scipy>=1.10.0

# =============================================================================
# Experiment Tracking & Logging
# =============================================================================
wandb>=0.15.0

# =============================================================================
# Progress & Visualization
# =============================================================================
rich>=13.0.0
tqdm>=4.65.0
matplotlib>=3.7.0
seaborn>=0.12.0

# =============================================================================
# Utilities
# =============================================================================
pyyaml>=6.0
omegaconf>=2.3.0

# =============================================================================
# Optional: For Jupyter Notebooks
# =============================================================================
jupyter>=1.0.0
ipywidgets>=8.0.0

# =============================================================================
# Optional: For accelerated training
# =============================================================================
# bitsandbytes>=0.41.0  # For 8-bit quantization
# flash-attn>=2.3.0     # For Flash Attention (requires CUDA)
# xformers>=0.0.22      # For memory-efficient attention
